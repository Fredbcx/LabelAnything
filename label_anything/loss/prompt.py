import torch
import torch.nn as nn

from torch.nn.functional import normalize, binary_cross_entropy
from einops import rearrange


class PromptContrastiveLoss(nn.Module):
    def __init__(self):
        """
        Computes the contrastive loss of the class prompts generated for each example in the support set. 
        """
        super().__init__()
        self.t_prime = nn.Parameter(torch.tensor([torch.log(torch.tensor(10))]))
        self.bias = nn.Parameter(torch.tensor([-10.0]))
        
    def forward(self, class_embeddings: torch.Tensor, flag_masks, flag_points, flag_boxes):
        """
        Arguments:
            class_embeddings (torch.Tensor): the class embeddings generated by the model (B x M x C x D)
        """
        ignore_index = -100
        B, M, C, D = class_embeddings.shape
        
        flag_points = flag_points.sum(dim=3) # B x M x C x N -> B x M x C
        flag_boxes = flag_boxes.sum(dim=3) # B x M x C x N -> B x M x C
        flags = (flag_masks + flag_points + flag_boxes)# B x M x C
        flags[:, :, 0] = 1 # The first class is always the background and no prompts are generated for it
        flags = rearrange(flags, "b m c -> b (m c) 1")
        valid_elements = (flags > 0).sum(dim=1) # B x 1
        flags = (~(flags.repeat(1, 1, M*C).bool())).float()
        flags = (~(flags + rearrange(flags, " b c d -> b d c")).bool())
        flags = torch.triu(flags)
        
        class_embeddings = rearrange(class_embeddings, "b m c d -> b (m c) d")
        class_embeddings = normalize(class_embeddings, p=2, dim=-1)
        dot_products = class_embeddings @ rearrange(class_embeddings, " b c d -> b d c")
        dot_products = dot_products * torch.exp(self.t_prime) + self.bias
        
        contrastive_matrix = torch.eye(C, device=class_embeddings.device)
        contrastive_matrix = contrastive_matrix.unsqueeze(0).repeat(B, M, M)
        contrastive_matrix = 2 * contrastive_matrix - 1
        loss = -torch.log(torch.sigmoid(dot_products * contrastive_matrix))
        return (loss / valid_elements.unsqueeze(2))[flags].sum() / B
        
        
        
        
        

experiment:
  # It contains all the about the grids and the group of runs:
  name: Classification # name of the logger platform experiment
  group: FirstGroup # name of group of experiments for the logger platform
  continue_with_errors: False # continue with other runs even if a run fails
  start_from_grid: 0 # skip grids in the grid search
  start_from_run: 0 # skip runs from the selected grid

parameters:
  # Contains the parameters to build the grid.
  # Each value should be a dict or a list
  tags: [mytag1, mytag2] # list of tags to attach to the run in logger platform
  dataset_interface: [examples/cifar10/Cifar10] # Path to the dataset interface class

  train_params:
    loss:
      name: [cross_entropy] # class loss name
      params:
    seed: [42] # random seed to set
    substitution_threshold: 0.1 # threshold
    num_points: 1 # number of points for class after the substitution
    max_epochs: 10
    logger: 8
    initial_lr: 0.0001
    optimizer: [AdamW]

  model:
    name: [lam_h] # path to model class or model name contained in EzDL or super-gradients
    checkpoint: [/path/to/your/model.pth] # model parameters

  dataset: # parameters depending on the class you defined for the dataset
    batch_size: [8]
    num_workers: [0]

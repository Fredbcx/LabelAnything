{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "sys.path.append(str(Path.cwd().parent / 'label_anything'))\n",
    "sys.path.append(str(Path.cwd().parent / 'label_anything' / 'data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nico/Development/LabelAnything/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, PILToTensor\n",
    "from label_anything.data.transforms import CustomNormalize, CustomResize\n",
    "from label_anything.data.dataset import LabelAnythingDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from label_anything.logger.text_logger import get_logger\n",
    "from label_anything.logger.utils import (\n",
    "    extract_boxes_from_tensor,\n",
    "    image_with_points,\n",
    "    structure_annotations\n",
    ")\n",
    "import comet_ml\n",
    "from label_anything.logger.image_logger import Logger\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "from torchvision.transforms.functional import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = Path.cwd().parent / \"data\" / \"raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_ml.init(project_name='label-anything')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/nicolafan/label-anything/9a07cd33c43b4ff99befa995ecaad922\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = comet_ml.Experiment()\n",
    "logger = Logger(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Compose([\n",
    "    CustomResize(1024),\n",
    "    PILToTensor(),\n",
    "    CustomNormalize(1024)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LabelAnythingDataset(\n",
    "    instances_path=RAW_DATA_DIR / \"annotations\" / \"instances_train2017.json\",\n",
    "    img_dir=RAW_DATA_DIR / \"train2017\",\n",
    "    preprocess=preprocess\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=8,\n",
    "    collate_fn=dataset.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, gt = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 3, 1024, 1024])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"images\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2], [81, 61, 1, 49], [1], [72, 1, 74], [72, 74, 76], [64, 44, 50, 51, 85, 55, 31], [50, 67], [81, 51, 44]]\n"
     ]
    }
   ],
   "source": [
    "logger.log_batch(0, 0, batch, dataset.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(image_tensor):\n",
    "    MEAN = np.array([123.675, 116.280, 103.530]) / 255\n",
    "    STD = np.array([58.395, 57.120, 57.375]) / 255\n",
    "    unnormalized_image = (image_tensor.numpy() * np.array(STD)[:, None, None]) + np.array(MEAN)[:, None, None]\n",
    "    unnormalized_image = (unnormalized_image * 255).astype(np.uint8)\n",
    "    unnormalized_image = np.moveaxis(unnormalized_image, 0, -1)\n",
    "    return Image.fromarray(unnormalized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = batch[\"prompt_masks\"][0, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = resize(mask.unsqueeze(0), (1024, 1024), interpolation=Image.NEAREST)\n",
    "mask = np.array(mask).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask.squeeze() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "polygons = []\n",
    "\n",
    "for obj in contours:\n",
    "    coords = []\n",
    "        \n",
    "    for point in obj:\n",
    "        coords.append(int(point[0][0]))\n",
    "        coords.append(int(point[0][1]))\n",
    "\n",
    "    polygons.append(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = batch[\"images\"][0, 2]\n",
    "mask = batch[\"prompt_masks\"][0, 2, 1]\n",
    "annotations_mask = structure_annotations(\n",
    "    polygons,\n",
    ")\n",
    "logger.log_image(\n",
    "    get_image(image),\n",
    "    annotations_mask,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

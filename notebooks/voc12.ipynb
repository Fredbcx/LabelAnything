{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from pycocotools import mask as mask_utils\n",
    "import xml.etree.ElementTree as ET\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import binary_dilation, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni utili\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2913\n"
     ]
    }
   ],
   "source": [
    "def get_items(root, ids):\n",
    "    images = []\n",
    "    all_boxes = []\n",
    "    all_masks = []\n",
    "    all_labels = []\n",
    "\n",
    "    for image_id in ids:\n",
    "        image = _get_images(root, image_id)\n",
    "        boxes, labels = _get_annotations(root, image_id)\n",
    "        masks = _get_masks(root, image_id)\n",
    "\n",
    "        images.append(image)\n",
    "        all_boxes.append(boxes)\n",
    "        all_masks.append(masks)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    return images, all_boxes, all_masks, all_labels\n",
    "\n",
    "\n",
    "def _read_image_ids(image_sets_file):\n",
    "    ids = []\n",
    "    with open(image_sets_file) as f:\n",
    "        for line in f:\n",
    "            ids.append(line.rstrip())\n",
    "    return ids\n",
    "\n",
    "\n",
    "def _get_images(root, image_id):\n",
    "    image_file = os.path.join(root, \"JPEGImages\", image_id + \".jpg\")\n",
    "    image = cv2.imread(str(image_file))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "\n",
    "def _get_masks(root, image_id):\n",
    "    mask_file = os.path.join(root, \"SegmentationClass\", image_id + \".png\")\n",
    "    mask_array = np.array(Image.open(mask_file))\n",
    "    unique_values = np.unique(mask_array)\n",
    "    masks = {}\n",
    "\n",
    "    for value in unique_values:\n",
    "        if value in [0, 255]:\n",
    "            # If the value is 0 or 255, add it to the mask for 0\n",
    "            _ = masks.get(0, np.zeros_like(mask_array)) | (mask_array == value)\n",
    "        else:\n",
    "            # Apply binary dilation before finding connected components\n",
    "            dilated_mask = binary_dilation(mask_array == value)\n",
    "            labeled_array, num_features = label(dilated_mask)\n",
    "            for i in range(1, num_features + 1):\n",
    "                masks[f\"{value}_{i}\"] = np.where(labeled_array == i, 1, 0)\n",
    "\n",
    "    rle_masks = {}\n",
    "    for key, value in masks.items():\n",
    "        rle = mask_utils.encode(np.asfortranarray(value.astype(np.uint8)))\n",
    "        rle[\"counts\"] = rle[\"counts\"].decode(\"utf-8\")  # Convert bytes to string\n",
    "        rle_masks[key] = rle\n",
    "\n",
    "    return rle_masks\n",
    "\n",
    "\n",
    "def _get_annotations(root, image_id):\n",
    "    annotation_file = os.path.join(root, \"Annotations\", image_id + \".xml\")\n",
    "    objects = ET.parse(annotation_file).findall(\"object\")\n",
    "    boxes = []\n",
    "    labels = []\n",
    "\n",
    "    for object in objects:\n",
    "        class_name = object.find(\"name\").text.lower().strip()\n",
    "        bbox = object.find(\"bndbox\")\n",
    "        x1 = float(bbox.find(\"xmin\").text) - 1\n",
    "        y1 = float(bbox.find(\"ymin\").text) - 1\n",
    "        x2 = float(bbox.find(\"xmax\").text) - 1\n",
    "        y2 = float(bbox.find(\"ymax\").text) - 1\n",
    "        boxes.append([x1, y1, x2, y2])\n",
    "        labels.append(class_name)\n",
    "\n",
    "    # return bbox y labels\n",
    "    return (np.array(boxes, dtype=np.float32), np.array(labels))\n",
    "\n",
    "\n",
    "# create the ids for images\n",
    "root = pathlib.Path(\"/home/emanuele/Dottorato/dataset-vari/VOCdevkit/VOC2012\")\n",
    "images_file = os.path.join(root, \"ImageSets\", \"Segmentation\", \"dataset.txt\")\n",
    "ids = _read_image_ids(images_file)\n",
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generazione items dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, boxes, polygons, labels = get_items(root, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'size': [281, 500], 'counts': '[cT11f84M2N2N101N100000O010O10000000000003M1O1O1O00O1O1LhGFY8:2011O1O1O1O00000O10O1O1O1O1O10000000O10O100000O0M4O001O1O0O2O000001O2H8I7NoQc2'}\n",
      "{'size': [281, 500], 'counts': 'Xel01g82N2O0000001O1O0000000000000000000000000000000000000000000000000000000000000000000000001O01O00000000000000000001O01O01O000000000001O0000000000000000000000000001O0001O001O000000000001O1OO1`0^O5L3K4N2M3N2N2N1O2N2N2N2QI]Nc60XIm1e65N3N1N200O00000000O1O11O1OO1O0AeI_N^6a1cI]N]6c1eIXNI1b6h1<00O00001O100O1O1O1O2N1M3O2N1O1O1IdHnN_7Q160OC[HGe77\\\\HIe75\\\\HKg71ZHOe71\\\\HOe70\\\\HNd72]HNb72_HN`73`HLMOV75mHKM2U75lHHO5T74lHG13T77jH6W7JhH4[7LfH4Y7LgH7V7IjH8U7GlHHO5T73mHG14S75lHG22T76jHHh76YHJg75ZHKg70]H0d7N]H2U8000000O1000000000O1000O10000000000000O10000000000000000000000000000000000000000000000000000000000000O001O10000000000000O0100000000000000000O0100000000000000000000000000000O01000000000000000000000001N2NmlQ1'}\n",
      "{'size': [281, 500], 'counts': 'aWf137;L6V7BkH:M6V7BkHQ1T7POkHo0W7810100N2N0G901UO[H`0g7@[H7m7Hc0N2Nab^2'}\n",
      "{'size': [281, 500], 'counts': 'S`65c82N;E2M4L3N2N10=D4L0N2000N2cNhHV1_7]OjH@Y7=f0K3K5McVm3'}\n"
     ]
    }
   ],
   "source": [
    "for enum, (box, rle, label) in enumerate(zip(boxes, polygons,labels)):\n",
    "    for b, (_, rle_value), l in zip(box, rle.items(), label):\n",
    "        print(rle_value)\n",
    "        l = rle_value\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S`65c82N;E2M4L3N2N10=D4L0N2000N2cNhHV1_7]OjH@Y7=f0K3K5McVm3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l['counts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Formatting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'info': {'description': 'VOC 2012 Dataset Annotations files',\n",
       "  'version': '1.0',\n",
       "  'year': 2024,\n",
       "  'contributor': 'CILAB',\n",
       "  'date_created': '02/01/2024'},\n",
       " 'images': [],\n",
       " 'annotations': [],\n",
       " 'categories': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances_voc12 = {\n",
    "    \"info\": {\n",
    "        \"description\": \"VOC 2012 Dataset Annotations files\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"year\": 2024,\n",
    "        \"contributor\": \"CILAB\", \n",
    "        \"date_created\": \"02/01/2024\",\n",
    "    },\n",
    "    \"images\": [\n",
    "        # {\n",
    "        #     \"file_name\": \"2007_000032\",\n",
    "        #     \"url\": \"VOC2012/JPEGImages/2007_000032.jpg\",\n",
    "        #     \"height\": 281,\n",
    "        #     \"width\": 500,\n",
    "        #     \"id\": 0,\n",
    "        # },\n",
    "        # {...},\n",
    "    ],\n",
    "    \"annotations\": [\n",
    "        # {\n",
    "        #     \"segmentation\": [\n",
    "        #         [\n",
    "        #             [117.0, 89.0],\n",
    "        #             [116.0, 90.0],\n",
    "        #             [109.0, 90.0],\n",
    "        #             [107.0, 92.0],\n",
    "        #             [134.0, 171.0],\n",
    "        #             [128.0, 171.0],\n",
    "        #             [127.0, 170.0],\n",
    "        #             [127.0, 137.0],\n",
    "        #         ]\n",
    "        #     ],\n",
    "        #     \"area\": 20098.5,\n",
    "        #     \"image_id\": 40,\n",
    "        #     \"bbox\": [118.0, 176.0, 330.0, 277.0],\n",
    "        #     \"category_id\": 9,\n",
    "        #     \"id\": 64,\n",
    "        # },\n",
    "        # {...},\n",
    "    ],\n",
    "    \"categories\": [\n",
    "        # {\"id\": 0, \"name\": \"sheep\"},\n",
    "        # {\"id\": 1, \"name\": \"bird\"},\n",
    "        # {\"id\": 2, \"name\": \"bus\"},\n",
    "        # {\"id\": 3, \"name\": \"cow\"},\n",
    "    ],\n",
    "}\n",
    "instances_voc12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create lvis style annotations for voc12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lvis_style_annotation(ids, images, boxes, rle_masks, labels, annotations):\n",
    "    # generate set of categories\n",
    "    annotations_images = []\n",
    "    annotations_segmentations = []\n",
    "\n",
    "    annotations_categories = [\n",
    "        {\"id\": i, \"name\": name} for i, name in enumerate(set(np.concatenate(labels)))\n",
    "    ]\n",
    "    category_to_id = {\n",
    "        category[\"name\"]: category[\"id\"] for category in annotations_categories\n",
    "    }\n",
    "\n",
    "    for enum, id_ in enumerate(ids):\n",
    "        # print(ids[i])\n",
    "        image = {\n",
    "            \"file_name\": id_,  # This is the only field that is compulsory\n",
    "            \"url\": f\"JPEGImages/{id_}.jpg\",\n",
    "            \"height\": images[enum].shape[0],\n",
    "            \"width\": images[enum].shape[1],\n",
    "            \"id\": enum,\n",
    "        }\n",
    "        annotations_images.append(image)\n",
    "\n",
    "    i = 0\n",
    "    for enum, (box, rle, label) in enumerate(zip(boxes, rle_masks, labels)):\n",
    "        for b, (_, rle_value), l in zip(box, rle.items(), label):\n",
    "            annotation = {\n",
    "                \"segmentation\": rle_value[\"counts\"],\n",
    "                \"area\": int(mask_utils.area(rle_value)),\n",
    "                \"image_id\": enum,\n",
    "                \"bbox\": b.tolist(),  # Assuming box is a list/array of [x_min, y_min, x_max, y_max]\n",
    "                \"category_id\": category_to_id[l],\n",
    "                \"id\": i,\n",
    "            }\n",
    "            annotations_segmentations.append(annotation)\n",
    "            i += 1\n",
    "\n",
    "    annotations[\"images\"] = annotations_images\n",
    "    annotations[\"annotations\"] = annotations_segmentations\n",
    "    annotations[\"categories\"] = annotations_categories\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate file, if you want to use it in the future\n",
    "annotations = create_lvis_style_annotation(\n",
    "    ids, images, boxes, polygons, labels, instances_voc12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmentation <class 'str'>\n",
      "area <class 'int'>\n",
      "image_id <class 'int'>\n",
      "bbox <class 'list'>\n",
      "category_id <class 'int'>\n",
      "id <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "for k,v in annotations.get(\"annotations\")[0].items():\n",
    "    print(k,type(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save file json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type uint32 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstances_voc12.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/json/encoder.py:432\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.11/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.11/json/encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.11/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.11/json/encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.11/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type uint32 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "with open(\"instances_voc12.json\", \"w\") as file:\n",
    "    json.dump(annotations, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/emanuele/Dottorato/dataset-vari/VOC12/JPEGImages/2007_000042.jpg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"license\": 4,\n",
    "    \"file_name\": \"000000397133.jpg\",\n",
    "    \"coco_url\": \"http://images.cocodataset.org/val2017/000000397133.jpg\",\n",
    "    \"height\": 427,\n",
    "    \"width\": 640,\n",
    "    \"date_captured\": \"2013-11-14 17:02:52\",\n",
    "    \"flickr_url\": \"http://farm7.staticflickr.com/6116/6255196340_da26cf2c9e_z.jpg\",\n",
    "    \"id\": 397133,\n",
    "}\n",
    "image = {\n",
    "    \"file_name\": \"2007_000042\",\n",
    "    \"url\": \"JPEGImages/2007_000042.jpg\",\n",
    "    \"height\": 335,\n",
    "    \"width\": 500,\n",
    "    \"id\": 3,\n",
    "}\n",
    "dataset_path = \"/home/emanuele/Dottorato/dataset-vari/VOC12\"\n",
    "(f'{dataset_path}/{image[\"url\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
